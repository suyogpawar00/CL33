{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e334c210",
   "metadata": {},
   "source": [
    "Data Visualization from Extraction Transformation and Loading (ETL) Process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e1e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('titanic_dataset.csv')\n",
    "df\n",
    "df.isnull().sum()\n",
    "df.notnull()\n",
    "df = df.fillna(0, inplace = False)\n",
    "df.isnull().sum()\n",
    "df1 = pd.read_csv('titanic_dataset.csv')\n",
    "df1.head()\n",
    "df1['Sex']\n",
    "df1['Sex'] = df1['Sex'].map({'male':1,'female':0})\n",
    "df1['Sex']\n",
    "df1.head()\n",
    "df1.isnull().sum()\n",
    "df1.dtypes\n",
    "df1['Age'] = df1['Age'].fillna(method = 'bfill')\n",
    "df1.head()\n",
    "df1.isnull().sum()\n",
    "df1['Age'] = df1['Age'].astype(int)\n",
    "df1['Age'].dtypes\n",
    "df1.dtypes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "target = ['Age','Fare']\n",
    "sc = StandardScaler()\n",
    "df1[target] = sc.fit_transform(df1[target])\n",
    "target\n",
    "print(df1)\n",
    "df1.head()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "target = ['Age','Fare']\n",
    "sc = MinMaxScaler()\n",
    "df1[target] = sc.fit_transform(df1[target])\n",
    "df1\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.hist(df['Fare'])\n",
    "plt.boxplot(df['Fare'])\n",
    "Q1 = df1['Fare'].quantile(0.25)\n",
    "Q3 = df1['Fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "width = 5\n",
    "lower = Q1 - (width * IQR)\n",
    "upper = Q3 + (width * IQR)\n",
    "\n",
    "# Remove outliers\n",
    "df1 = df1[(df1['Fare'] >= lower) & (df1['Fare'] <= upper)]\n",
    "\n",
    "# Now the 'Fare' column contains data without outliers\n",
    "print(df1.head())\n",
    "df1.to_excel('titanic_cleaned.xlsx', index=False)\n",
    "plt.hist(df1['Age'])\n",
    "plt.hist(x = df1['Fare'], align = 'mid')\n",
    "import seaborn as sns\n",
    "sns.pairplot(df1)\n",
    "sns.histplot(df['Age'], kde = True)\n",
    "sns.barplot(df1['Age'])\n",
    "sns.boxplot(df1['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20225fe",
   "metadata": {},
   "source": [
    "Perform the data classification algorithm using any Classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3143f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Feature scaling\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled, X_test_scaled = scaler.transform(X_train), scaler.transform(X_test)\n",
    "# Initialize and train the logistic regression model\n",
    "logreg = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "# Model evaluation\n",
    "train_accuracy, test_accuracy = accuracy_score(y_train, logreg.predict(X_train_scaled)), accuracy_score(y_test, logreg.predict(X_test_scaled))\n",
    "print(\"Training Accuracy:\", train_accuracy, \"\\nTesting Accuracy:\", test_accuracy)\n",
    "# Additional evaluation metrics\n",
    "print(\"Classification Report on Test Data:\\n\", classification_report(y_test, logreg.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362509a",
   "metadata": {},
   "source": [
    "Perform the data clustering algorithm using any Clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afc305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the wine dataset\n",
    "data = load_wine()\n",
    "\n",
    "# Create a DataFrame\n",
    "wine_df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(wine_df)\n",
    "\n",
    "# Determine the optimal number of clusters using silhouette score\n",
    "silhouette_scores = []\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(scaled_features)\n",
    "    silhouette_avg = silhouette_score(scaled_features, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plotting silhouette scores to find optimal number of clusters\n",
    "plt.plot(range(2, 11), silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for K-means Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Based on the silhouette scores, let's choose 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "wine_df['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Plotting the clusters\n",
    "plt.scatter(wine_df['alcohol'], wine_df['flavanoids'], c=wine_df['cluster'], cmap='viridis')\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Flavanoids')\n",
    "plt.title('Wine Clusters')\n",
    "plt.show()\n",
    "\n",
    "ORRRR\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "# Features\n",
    "X = iris.data \n",
    "# Initialize KMeans with the number of clusters (3 for the iris dataset)\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "# Fit KMeans to the data\n",
    "kmeans.fit(X)\n",
    "# Get the cluster centroids and labels\n",
    "centroids = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_\n",
    "# Visualizing the clusters (assuming 2D data for simplicity)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, c='red')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('FeatureÂ 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babeb009",
   "metadata": {},
   "source": [
    "Develop a MapReduce program to calculate the frequency of a given word in a given\n",
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def mapper():\n",
    "    for line in sys.stdin:\n",
    "        name_scores = line.strip().split(\", \")  # Split the line using comma as the delimiter\n",
    "        name = name_scores[0]\n",
    "        scores = list(map(int, name_scores[1].split()))  # Split scores using spaces as the delimiter\n",
    "        average_score = sum(scores) / len(scores)\n",
    "        grade = assign_grade(average_score)\n",
    "        print(f\"{name}\\t{grade}\")\n",
    "\n",
    "def assign_grade(average_score):\n",
    "    if average_score >= 90:\n",
    "        return \"A\"\n",
    "    elif average_score >= 80:\n",
    "        return \"B\"\n",
    "    elif average_score >= 70:\n",
    "        return \"C\"\n",
    "    elif average_score >= 60:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"F\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mapper()\n",
    "    \n",
    "REDUCER\n",
    "\n",
    "import sys\n",
    "\n",
    "def reducer():\n",
    "    grade_counts = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'F': 0}\n",
    "\n",
    "    for line in sys.stdin:\n",
    "        name, grade = line.strip().split(\"\\t\")\n",
    "        grade_counts[grade] += 1\n",
    "\n",
    "    for grade, count in grade_counts.items():\n",
    "        print(f\"Grade {grade}: {count} students\")\n",
    "        \n",
    "if __name__ ==\"__main__\":\n",
    "    reducer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7dee4",
   "metadata": {},
   "source": [
    "Implement Matrix Multiplication using Map-Reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670663a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "with open(sys.argv[1],'r') as f:\n",
    "\tmatrix_A = [list(map(int, line.strip().split())) for line in f]\n",
    "    \n",
    "with open(sys.argv[2],'r') as f:\n",
    "\tmatrix_B = [list(map(int, line.strip().split())) for line in f]\n",
    "for i in range(len(matrix_A)):\n",
    "\tfor j in range(len(matrix_B[0])):\n",
    "\t\tfor k in range(len(matrix_B)):\n",
    "\t\t\tprint(f\"{i}, {j}\\t {matrix_A[i][k]}, {matrix_B[k][j]}\")\n",
    "            \n",
    "Reducer\n",
    "import sys\n",
    "\n",
    "current_key = None\n",
    "current_values = []\n",
    "\n",
    "for line in sys.stdin:\n",
    "\tkey, value = line.strip().split('\\t')\n",
    "\n",
    "\n",
    "\tif current_key == None:\n",
    "\t\tcurrent_key = key\n",
    "\tif key != current_key:\n",
    "\t\tresult = 0\n",
    "\t\tfor value_pair in current_values:\n",
    "\t\t\tvalue1, value2 = value_pair.split(',')\n",
    "\t\t\tresult += int(value1)*int(value2)\n",
    "\t\tprint(f\"{current_key}\\t{result}\")\n",
    "\t\t\n",
    "\t\tcurrent_key = key\n",
    "\t\tcurrent_values = []\n",
    "\t\t\n",
    "\tcurrent_values.append(value)\n",
    "\t\n",
    "result = 0\n",
    "\n",
    "for value_pair in current_values:\n",
    "\tvalue1, value2 = value_pair.split(',')\n",
    "\tresult += int(value1) * int(value2)\n",
    "print(f\"{current_key}\\t{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a3181",
   "metadata": {},
   "source": [
    "Develop a MapReduce program to find the grades of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e047e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def mapper():\n",
    "    for line in sys.stdin:\n",
    "        name_scores = line.strip().split(\", \")  # Split the line using comma as the delimiter\n",
    "        name = name_scores[0]\n",
    "        scores = list(map(int, name_scores[1].split()))  # Split scores using spaces as the delimiter\n",
    "        average_score = sum(scores) / len(scores)\n",
    "        grade = assign_grade(average_score)\n",
    "        print(f\"{name}\\t{grade}\")\n",
    "\n",
    "def assign_grade(average_score):\n",
    "    if average_score >= 90:\n",
    "        return \"A\"\n",
    "    elif average_score >= 80:\n",
    "        return \"B\"\n",
    "    elif average_score >= 70:\n",
    "        return \"C\"\n",
    "    elif average_score >= 60:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"F\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mapper()\n",
    "    \n",
    "Reducer\n",
    "import sys\n",
    "\n",
    "def reducer():\n",
    "    grade_counts = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'F': 0}\n",
    "\n",
    "    for line in sys.stdin:\n",
    "        name, grade = line.strip().split(\"\\t\")\n",
    "        grade_counts[grade] += 1\n",
    "\n",
    "    for grade, count in grade_counts.items():\n",
    "        print(f\"Grade {grade}: {count} students\")\n",
    "        \n",
    "if __name__ ==\"__main__\":\n",
    "    reducer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f4725e",
   "metadata": {},
   "source": [
    "Mongo DB: Installation and Creation of database and Collection CRUD Document:\n",
    "Insert, Query, Update and Delete Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a792af",
   "metadata": {},
   "outputs": [],
   "source": [
    "show db\n",
    "use mydatabase\n",
    "db.createCollection(\"mycollection\")\n",
    "db.mycollection.insertOne({ name: \"John\", age: 30 })\n",
    "db.mycollection.insertMany([{name: \"John\", age:30},{name: \"Sid\", age:22}])\n",
    "db.mycollection.find()\n",
    "db.mycollection.updateOne({ name: \"John\" }, { $set: { age: 35 } })\n",
    "db.mycollection.deleteOne({ name: \"John\" })\n",
    "# db.mycollection.drop()\n",
    "# db.dropDatabase()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
